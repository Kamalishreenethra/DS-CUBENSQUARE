{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3757bf51",
   "metadata": {},
   "source": [
    "# ğŸ“… Day 11: Random Forests & Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb2deff",
   "metadata": {},
   "source": [
    "## ğŸ¯ Objective\n",
    "Learn what ensemble learning is and how to use a Random Forest classifier to improve performance over a single decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b1f99",
   "metadata": {},
   "source": [
    "## ğŸŒ² What is a Random Forest?\n",
    "- An ensemble method that builds multiple decision trees and merges their results to improve accuracy and reduce overfitting.\n",
    "- Works well with both classification and regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b114d1fd",
   "metadata": {},
   "source": [
    "## ğŸ¤ Why Ensemble Learning?\n",
    "- Combines multiple weak learners to form a strong learner\n",
    "- Reduces variance, improves generalization\n",
    "- Types: Bagging (Random Forest), Boosting, Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760073a9",
   "metadata": {},
   "source": [
    "## ğŸ“¦ StepÂ 1â€¯â€“â€¯Load & Prepare Data (Breast Cancer Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7213f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "# Split & scale\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac65de2",
   "metadata": {},
   "source": [
    "## ğŸŒ³ StepÂ 2â€¯â€“â€¯Train a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200fbc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "print('Random Forest Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a23ea",
   "metadata": {},
   "source": [
    "## ğŸ“Š StepÂ 3â€¯â€“â€¯Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d4c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "importances = rf_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.bar(range(X.shape[1]), importances[indices], align='center')\n",
    "plt.xticks(range(X.shape[1]), df.columns[indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ee37c",
   "metadata": {},
   "source": [
    "## ğŸ” StepÂ 4â€¯â€“â€¯Try Different Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444da6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change number of trees and max depth\n",
    "rf_model_alt = RandomForestClassifier(n_estimators=50, max_depth=3, random_state=42)\n",
    "rf_model_alt.fit(X_train_scaled, y_train)\n",
    "alt_pred = rf_model_alt.predict(X_test_scaled)\n",
    "print('Alt Random Forest Accuracy:', accuracy_score(y_test, alt_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c852a62f",
   "metadata": {},
   "source": [
    "## âœ… Summary\n",
    "- Random Forests average many trees to reduce overfitting.\n",
    "- More stable than a single Decision Tree.\n",
    "- Feature importance helps interpret models."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
