{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8515f1e6",
   "metadata": {},
   "source": [
    "# üèÅ Day 15: Capstone Mini Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9582a818",
   "metadata": {},
   "source": [
    "## üéØ Objective\n",
    "Apply everything you've learned across the internship to solve a real-world classification problem using the end-to-end ML pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c57c214",
   "metadata": {},
   "source": [
    "## üí° Project: Predict Titanic Survivors\n",
    "We'll use the Titanic dataset to predict whether a passenger survived based on features like age, gender, class, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eb9dd1",
   "metadata": {},
   "source": [
    "## ‚úÖ Workflow:\n",
    "1. Load dataset\n",
    "2. Clean and preprocess data\n",
    "3. Encode categorical features\n",
    "4. Scale numerical features\n",
    "5. Split into train-test sets\n",
    "6. Train multiple models (Logistic, Random Forest, SVM)\n",
    "7. Compare model performance\n",
    "8. Visualize ROC curves\n",
    "9. Export the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9400e6eb",
   "metadata": {},
   "source": [
    "## üì¶ Step 1 ‚Äì Load & Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9121c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ea427",
   "metadata": {},
   "source": [
    "## üîç Step 2 ‚Äì Data Cleaning & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba6729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "# Fill missing Age with median\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "# Fill missing Embarked with mode\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae14285",
   "metadata": {},
   "source": [
    "## üî† Step 3 ‚Äì Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f83944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd52161",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 4 ‚Äì Split and Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2805f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5ea1ba",
   "metadata": {},
   "source": [
    "## üß™ Step 5 ‚Äì Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c97b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(probability=True)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    print(f'{name} Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb0027",
   "metadata": {},
   "source": [
    "## üìä Step 6 ‚Äì Compare ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce816771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for name, model in models.items():\n",
    "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Model ROC Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f646c49b",
   "metadata": {},
   "source": [
    "## üíæ Step 7 ‚Äì Save the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649ee07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "best_model = models['Random Forest']  # Assuming it's best based on AUC\n",
    "joblib.dump(best_model, 'titanic_model.pkl')\n",
    "print('Model saved as titanic_model.pkl')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
